# -*- coding: utf-8 -*-
"""assignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qNenGKgqm82u_TmoC2ver-CN5EREc-S4
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import datasets
import matplotlib.pyplot as plt
import time

"""prepare the dataset"""

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images = train_images / 255.0
test_images = test_images / 255.0
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

"""Define the different models. Conv_size, fc_size and dropout rate"""

# Different conv size models
models_conv = []
conv_sizes = [32, 64, 128]

for conv_size in conv_sizes:
    model = keras.Sequential([
        layers.Conv2D(conv_size, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(2*conv_size, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),

        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(10, activation='softmax')
    ])
    models_conv.append(model)

# Different fc size models
models_fc = []
fc_sizes = [128, 256, 512]

for fc_size in fc_sizes:
    model = keras.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),

        layers.Flatten(),
        layers.Dense(fc_size, activation='relu'),
        layers.Dense(10, activation='softmax')
    ])
    models_fc.append(model)

# Different dropout rate models
models_dropout = []
dropout_rates = [0.0, 0.25, 0.5]

for dropout_rate in dropout_rates:
    model = keras.Sequential([
        layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),

        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(dropout_rate),
        layers.Dense(10, activation='softmax')
    ])
    models_dropout.append(model)

"""Train models"""

all_models = models_conv + models_fc + models_dropout
training_times = []
accuracies = []
losses = []
for i, model in enumerate(all_models):
  model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])

  print(f"Training Model {i + 1}")
  start_time = time.time()  # start timing
  model.fit(train_images, train_labels, epochs=10, verbose=0)
  end_time = time.time()    # end timing

  elapsed_time = end_time - start_time
  training_times.append(elapsed_time)
  print(f"Training time for Model {i + 1}: {elapsed_time:.2f} seconds")
  # evaluate and record the loss and acc for each model
  test_loss, test_acc = model.evaluate(test_images, test_labels)
  accuracies.append(test_acc)
  losses.append(test_loss)

"""Data Visualization"""

# All models' accuracy graph
plt.figure(figsize=(10, 6))
plt.bar(range(len(all_models)), accuracies)
plt.title("Accuracy for Different Models")
plt.xticks(range(len(all_models)), [f"Model {i + 1}" for i in range(len(all_models))])
plt.xlabel("Model")
plt.ylabel("Accuracy")
plt.show()

# All models' loss graph
plt.figure(figsize=(10, 6))
plt.bar(range(len(all_models)), losses)
plt.title("Loss for Different Models")
plt.xticks(range(len(all_models)), [f"Model {i + 1}" for i in range(len(all_models))])
plt.xlabel("Model")
plt.ylabel("Loss")
plt.show()

# All models' runtime graph
plt.figure(figsize=(10, 6))
plt.bar(range(len(all_models)), training_times)
plt.title("Training Time for Different Models")
plt.xticks(range(len(all_models)), [f"Model {i + 1}" for i in range(len(all_models))])
plt.xlabel("Model")
plt.ylabel("Training Time (seconds)")
plt.show()

# Conv size vs Accuracy graph
conv_sizes = [32, 64, 128]
conv_acc = accuracies[:len(conv_sizes)]

plt.figure(figsize=(8, 6))
plt.plot(conv_sizes, conv_acc, marker='o')
plt.title("Convolutional Size vs Accuracy")
plt.xlabel("Convolutional Size")
plt.ylabel("Accuracy")
plt.grid(True)
plt.show()

# Conv size vs Loss graph
conv_loss = losses[:len(conv_sizes)]

plt.figure(figsize=(8, 6))
plt.plot(conv_sizes, conv_loss, marker='o')
plt.title("Convolutional Size vs Loss")
plt.xlabel("Convolutional Size")
plt.ylabel("Loss")
plt.grid(True)
plt.show()

# Fc vs Accuracy graph
fc_sizes = [128, 256, 512]
fc_acc = accuracies[len(conv_sizes):len(conv_sizes) + len(fc_sizes)]
plt.figure(figsize=(8, 6))
plt.plot(fc_sizes, fc_acc, marker='o')
plt.title("Fully Connected Size vs Accuracy")
plt.xlabel("Fully Connected Size")
plt.ylabel("Accuracy")
plt.grid(True)
plt.show()

# Fc vs Loss graph
fc_loss = losses[len(conv_sizes):len(conv_sizes) + len(fc_sizes)]

plt.figure(figsize=(8, 6))
plt.plot(fc_sizes, fc_loss, marker='o')
plt.title("Fully Connected Size vs Loss")
plt.xlabel("Fully Connected Size")
plt.ylabel("Loss")
plt.grid(True)
plt.show()

# Dropout rate vs Accuracy graph
dropout_rates = [0.0, 0.25, 0.5]
dropout_acc = accuracies[len(conv_sizes) + len(fc_sizes):]
plt.figure(figsize=(8, 6))
plt.plot(dropout_rates, dropout_acc, marker='o')
plt.title("Dropout Rate vs Accuracy")
plt.xlabel("Dropout Rate")
plt.ylabel("Accuracy")
plt.grid(True)
plt.show()

# Dropout rate vs Loss graph
dropout_loss = losses[len(conv_sizes) + len(fc_sizes):]

plt.figure(figsize=(8, 6))
plt.plot(dropout_rates, dropout_loss, marker='o')
plt.title("Dropout Rate vs Loss")
plt.xlabel("Dropout Rate")
plt.ylabel("Loss")
plt.grid(True)
plt.show()